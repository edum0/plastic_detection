{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a6ffc1-ffdc-4e3f-964a-468b384a7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 812 files belonging to 6 classes.\n",
      "Using 650 files for training.\n",
      "Found 812 files belonging to 6 classes.\n",
      "Using 162 files for validation.\n",
      "Total training batches: tf.Tensor(21, shape=(), dtype=int64)\n",
      "Counter({'jpg': 812})\n",
      "Classes identified: ['HDPE', 'LDPE', 'PET', 'PP', 'PS', 'PVC']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_path = r\"C:\\Users\\armaa\\Downloads\\Dataset\"\n",
    "\n",
    "\n",
    "# Parameters\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Load training and validation sets (80/20 split)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode = \"rgb\",\n",
    "    labels = \"inferred\"\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode = \"rgb\",\n",
    "    labels = \"inferred\"\n",
    ")\n",
    "\n",
    "print(\"Total training batches:\", tf.data.experimental.cardinality(train_ds))\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def check_images(folder):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            try:\n",
    "                img = Image.open(path)\n",
    "                img.verify()\n",
    "            except:\n",
    "                print(\"Removing corrupted file:\", path)\n",
    "                os.remove(path)\n",
    "\n",
    "check_images(data_path)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess(image,label):\n",
    "    image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "    return image,label\n",
    "\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "def one_hot_labels(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_labels, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(one_hot_labels, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "extensions = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        ext = file.split('.')[-1].lower()\n",
    "        extensions.append(ext)\n",
    "\n",
    "print(Counter(extensions))\n",
    "\n",
    "\n",
    "print(f\"Classes identified: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89efb90e-09c6-4ded-b2f0-e927911b2f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetv2-b2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetv2-b2 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)                │       \u001b[38;5;34m8,769,374\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> (33.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,769,374\u001b[0m (33.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> (33.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,769,374\u001b[0m (33.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_aug = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomTranslation(0.1,0.1),\n",
    "])\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetV2B2(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (224,224,3),\n",
    "    pooling = 'avg',\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    data_aug,\n",
    "    base_model,\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(384,activation = 'relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9feafc-fac9-473d-81e1-621d35a5c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 588ms/step - accuracy: 0.2815 - loss: 2.3199 - val_accuracy: 0.5370 - val_loss: 1.4810\n",
      "Epoch 2/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.4831 - loss: 1.5205 - val_accuracy: 0.5988 - val_loss: 1.2885\n",
      "Epoch 3/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.5323 - loss: 1.4363 - val_accuracy: 0.6358 - val_loss: 1.1884\n",
      "Epoch 4/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.6185 - loss: 1.1940 - val_accuracy: 0.7037 - val_loss: 1.1118\n",
      "Epoch 5/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.6800 - loss: 1.0540 - val_accuracy: 0.7099 - val_loss: 1.0538\n",
      "Epoch 6/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.6923 - loss: 0.9977 - val_accuracy: 0.7160 - val_loss: 1.0136\n",
      "Epoch 7/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 446ms/step - accuracy: 0.7262 - loss: 0.9248 - val_accuracy: 0.7222 - val_loss: 0.9760\n",
      "Epoch 8/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.7308 - loss: 0.9206 - val_accuracy: 0.7160 - val_loss: 0.9512\n",
      "Epoch 9/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.7585 - loss: 0.8267 - val_accuracy: 0.7160 - val_loss: 0.9172\n",
      "Epoch 10/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.7554 - loss: 0.8378 - val_accuracy: 0.7407 - val_loss: 0.8984\n",
      "Epoch 11/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.7846 - loss: 0.7695 - val_accuracy: 0.7346 - val_loss: 0.8992\n",
      "Epoch 12/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 383ms/step - accuracy: 0.8123 - loss: 0.7301 - val_accuracy: 0.7407 - val_loss: 0.8987\n",
      "Epoch 13/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.7969 - loss: 0.7118 - val_accuracy: 0.7222 - val_loss: 0.8878\n",
      "Epoch 14/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.8200 - loss: 0.7002 - val_accuracy: 0.7346 - val_loss: 0.8694\n",
      "Epoch 15/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.8446 - loss: 0.6377 - val_accuracy: 0.7346 - val_loss: 0.8961\n",
      "Epoch 16/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 443ms/step - accuracy: 0.8631 - loss: 0.6385 - val_accuracy: 0.7469 - val_loss: 0.9053\n",
      "Epoch 17/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.8492 - loss: 0.6569 - val_accuracy: 0.7407 - val_loss: 0.9176\n",
      "Epoch 18/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.8554 - loss: 0.5773 - val_accuracy: 0.7593 - val_loss: 0.9268\n",
      "Epoch 19/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.8492 - loss: 0.6220 - val_accuracy: 0.7593 - val_loss: 0.9078\n",
      "Epoch 20/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.8477 - loss: 0.6296 - val_accuracy: 0.7593 - val_loss: 0.9113\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=20,callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9d2054-aea8-49e1-80a2-af4c1d93a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 617ms/step - accuracy: 0.8046 - loss: 0.7027 - val_accuracy: 0.7531 - val_loss: 0.8773\n",
      "Epoch 2/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.8385 - loss: 0.6780 - val_accuracy: 0.7407 - val_loss: 0.8831\n",
      "Epoch 3/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.8385 - loss: 0.6689 - val_accuracy: 0.7469 - val_loss: 0.8798\n",
      "Epoch 4/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 436ms/step - accuracy: 0.8492 - loss: 0.6552 - val_accuracy: 0.7346 - val_loss: 0.8821\n",
      "Epoch 5/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.8308 - loss: 0.6777 - val_accuracy: 0.7407 - val_loss: 0.8818\n",
      "Epoch 6/15\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 436ms/step - accuracy: 0.8585 - loss: 0.6416 - val_accuracy: 0.7469 - val_loss: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bc6ec54250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-6),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=15,callbacks = [callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35756b5-511e-4e71-9a3c-818d5f24270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"plastic_model_3.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fee569-0a8a-42ee-88d1-47b203916d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
